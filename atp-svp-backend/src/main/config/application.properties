spring.resources.static-locations=file:./web/
atp-svp.web.root-page=web/index.html
server.port=${HTTP_PORT:8080}
server.forward-headers-strategy=NATIVE
logging.level.org.qubership.atp.svp=${LOG_LEVEL:INFO}
atp.integration.enabled=${ATP_INTEGRATION_ENABLED:false}
spring.main.allow-circular-references=true
service.pod-name=${HOSTNAME:localhost}
## ==================Undertow========================
#replacement="server.undertow.threads.io" on SpringBoot version 2.5.x
server.undertow.io-threads=${UNDERTOW_THREADS_IO:18}
#replacement="server.undertow.threads.worker" on SpringBoot version 2.5.x
server.undertow.worker-threads=${UNDERTOW_THREADS_WORKER:144}
##==================atp-svp=====================
svp.projects.config.path=${PROJECTS_CONFIG_PATH:./config/project}
svp.projects.config.name=${PROJECTS_CONFIG_NAME:projects_configs.json}
svp.session.lifespan=${SESSION_LIFESPAN:1800}
svp.deferred-search-results.lifespan.sec=${DEFERRED_SEARCH_RESULTS_LIFESPAN_SEC:600}
##==================ThreadPool========================
svp.getting.info.thread.pool.core.size=${SVP_GETTING_INFO_THREAD_POOL_CORE_SIZE:20}
svp.getting.info.thread.pool.max.size=${SVP_GETTING_INFO_THREAD_POOL_MAX_SIZE:200}
svp.getting.info.thread.pool.queue.capacity=${SVP_GETTING_INFO_THREAD_POOL_QUEUE_CAPACITY:0}
svp.validation.thread.pool.core.size=${SVP_VALIDATION_THREAD_POOL_CORE_SIZE:20}
svp.validation.thread.pool.max.size=${SVP_VALIDATION_THREAD_POOL_MAX_SIZE:200}
svp.validation.thread.pool.queue.capacity=${SVP_VALIDATION_THREAD_POOL_QUEUE_CAPACITY:0}
##==================atp-auth-spring-boot-starter=====================
spring.profiles.active=${SPRING_PROFILES:disable-security}
spring.cache.cache-names=projects
spring.cache.caffeine.spec=maximumSize=100, expireAfterAccess=120s, expireAfterWrite=120s, recordStats
keycloak.resource=${KEYCLOAK_CLIENT_NAME:atp-svp}
keycloak.credentials.secret=${KEYCLOAK_SECRET:""}
keycloak.enabled=${KEYCLOAK_ENABLED:false}
keycloak.bearer-only=true
keycloak.realm=${KEYCLOAK_REALM:testRealm}
keycloak.auth-server-url=${KEYCLOAK_AUTH_URL:localhost}
atp-auth.project_info_endpoint=${PROJECT_INFO_ENDPOINT:/api/v1/users/projects}
atp-auth.enable-m2m=true
atp-auth.headers.content-security-policy=${CONTENT_SECURITY_POLICY:default-src 'self' *}
##==================Integration with Spring Cloud======================
spring.main.allow-bean-definition-overriding=true
spring.application.name=${SERVICE_NAME:atp-svp}
eureka.client.serviceUrl.defaultZone=${SERVICE_REGISTRY_URL:http://atp-registry-service:8761/eureka}
eureka.client.enabled=${EUREKA_CLIENT_ENABLED:false}
atp.service.public=${ATP_SERVICE_PUBLIC:true}
atp.service.path=${ATP_SERVICE_PATH:/api/atp-svp/v1/**}
atp.catalogue.ui.url=${CATALOGUE_URL:}
atp.openshift.host=${OPENSHIFT_HOST:}
atp.openshift.project=${OPENSHIFT_PROJECT:}
eureka.instance.preferIpAddress=true
spring.sleuth.integration.websockets.enabled=false
spring.mvc.pathmatch.matching-strategy=ANT_PATH_MATCHER
#==================locale resolver==================================
locale.resolver.lang=${LOCALE_RESOLVER:en}
## ================== Feign ========================
feign.httpclient.disableSslValidation=true
feign.httpclient.enabled=false
feign.okhttp.enabled=true
feign.client.config.default.connectTimeout=${FEIGN_CONNECT_TIMEOUT:300000}
feign.client.config.default.readTimeout=${FEIGN_READ_TIMEOUT:300000}
## environments
feign.atp.environments.url=${FEIGN_ATP_ENVIRONMENTS_URL:}
feign.atp.environments.name=${FEIGN_ATP_ENVIRONMENTS_NAME:ATP-ENVIRONMENTS}
feign.atp.environments.route=${FEIGN_ATP_ENVIRONMENTS_ROUTE:}
## bulkValidator
feign.atp.bulkValidator.url=${FEIGN_ATP_BULKVALIDATOR_URL:}
feign.atp.bulkValidator.name=${FEIGN_ATP_BULKVALIDATOR_NAME:ATP-BV}
feign.atp.bulkValidator.route=${FEIGN_ATP_BULKVALIDATOR_ROUTE:}
##catalogue - user management
feign.atp.users.url=${FEIGN_ATP_USERS_URL:}
feign.atp.users.name=${FEIGN_ATP_USERS_NAME:ATP-USERS-BACKEND}
feign.atp.users.route=${FEIGN_ATP_USERS_ROUTE:api/atp-users-backend/v1}
## LogCollector
feign.atp.logcollector.url=${FEIGN_ATP_LOGCOLLECTOR_URL:}
feign.atp.logcollector.name=${FEIGN_ATP_LOGCOLLECTOR_NAME:ATP-LOGCOLLECTOR}
feign.atp.logcollector.route=${FEIGN_ATP_LOGCOLLECTOR_ROUTE:}
##==================Zipkin=====================
spring.sleuth.enabled=${ZIPKIN_ENABLE:false}
spring.sleuth.sampler.probability=${ZIPKIN_PROBABILITY:1.0}
spring.zipkin.baseUrl=${ZIPKIN_URL:http://127.0.0.1:9411}
spring.sleuth.web.additional-skip-pattern=/rest/deployment/liveness|/rest/deployment/readiness
##================== atp-crypt =====================
atp.crypto.key=${ATP_CRYPTO_KEY}
atp.crypto.privateKey=${ATP_CRYPTO_PRIVATE_KEY}
##==================Kafka========================
kafka.enable=${KAFKA_ENABLE:false}
spring.kafka.bootstrap-servers=${KAFKA_SERVERS:kafka:9092}
spring.kafka.consumer.client-id=${KAFKA_CLIENT_ID:svp}
spring.kafka.consumer.group-id=${KAFKA_GROUP_ID:svp}
spring.kafka.consumer.auto-offset-reset=latest
kafka.project.event.enable=${KAFKA_PROJECT_EVENT_ENABLE:false}
kafka.project.event.consumer.topic.name=${KAFKA_TOPIC:catalog_notification_topic}
kafka.topic.end.logcollector=${KAFKA_TOPIC_END_LOGCOLLECTOR:logcollector_search_notification_topic}
kafka.logcollector.event.enable=${KAFKA_LOGCOLLECTOR_EVENT_ENABLE:false}
kafka.topic.end.svp.partitions=${KAFKA_SVP_GET_INFO_TOPIC_PARTITIONS:1}
kafka.topic.end.svp.replication=${KAFKA_SVP_GET_INFO_TOPIC_REPLICATION:3}
kafka.topic.end.svp=${KAFKA_SVP_GET_INFO_TOPIC:svp_get_info_notification_topic}
kafka.service.entities.topic=${KAFKA_SERVICE_ENTITIES_TOPIC:service_entities}
kafka.service.entities.topic.partitions=${KAFKA_SERVICE_ENTITIES_TOPIC_PARTITIONS:1}
kafka.service.entities.topic.replicas=${KAFKA_SERVICE_ENTITIES_TOPIC_REPLICATION_FACTOR:3}
service.entities.migration.enabled=${SERVICE_ENTITIES_MIGRATION_ENABLED:false}
kafka.svp.event.enable=${KAFKA_SVP_EVENT_ENABLE:false}
spring.kafka.producer.bootstrap-servers=${KAFKA_SERVERS:kafka:9092}
#==================Monitoring========================================
management.server.port=${MONITOR_PORT:8090}
management.endpoints.web.exposure.include=${MONITOR_WEB_EXPOSE:prometheus,info,scheduledtasks}
management.endpoints.web.base-path=${MONITOR_WEB_BASE:/}
management.endpoints.web.path-mapping.prometheus=${MONITOR_WEB_MAP_PROM:metrics}
management.endpoints.enabled-by-default=false
management.endpoint.prometheus.enabled=true
management.endpoint.flowable.enabled=true
management.metrics.tags.application=${spring.application.name}
#==================UI-URL-BV========================================
atp.bv.url=${ATP_BVT_URL:}
#==================RestConfig========================================
svp.rest.config.timeout.sec=${REST_TIMEOUT_SEC:300}
#==================Common-logging========================================
atp.logging.resttemplate.headers=${ATP_HTTP_LOGGING_HEADERS:true}
atp.logging.resttemplate.headers.ignore=${ATP_HTTP_LOGGING_HEADERS_IGNORE: }
atp.logging.feignclient.headers=${ATP_HTTP_LOGGING_HEADERS:true}
atp.logging.feignclient.headers.ignore=${ATP_HTTP_LOGGING_HEADERS_IGNORE: }
atp.logging.controller.headers=${ATP_HTTP_LOGGING_HEADERS:true}
atp.logging.controller.headers.ignore=${ATP_HTTP_LOGGING_HEADERS_IGNORE:}
atp.logging.controller.uri.ignore=${ATP_HTTP_LOGGING_URI_IGNORE:/rest/deployment/readiness /rest/deployment/liveness}
#==================Graceful shutdown========================================
server.shutdown=graceful
## ==================Swagger========================
springdoc.api-docs.enabled=${SWAGGER_ENABLED:true}
#===================== postgresql =============================
spring.datasource.type=com.zaxxer.hikari.HikariDataSource
spring.datasource.url=jdbc:postgresql://${PG_DB_ADDR:localhost}:${PG_DB_PORT:5432}/${SVP_DB:atp_svp}
spring.datasource.hikari.username=${SVP_DB_USER:postgres}
spring.datasource.hikari.password=${SVP_DB_PASSWORD:admin}
spring.datasource.hikari.driver-class-name=org.postgresql.Driver
spring.datasource.hikari.poolName=SpringBootJPAHikariCP
spring.datasource.hikari.minimumIdle=${HIKARI_MIN_POOL_SIZE:10}
spring.datasource.hikari.maximumPoolSize=${HIKARI_MAX_POOL_SIZE:100}
spring.datasource.hikari.idleTimeout=30000
spring.datasource.hikari.maxLifetime=2000000
spring.datasource.hikari.connectionTimeout=30000
spring.datasource.hikari.leak-detection-threshold=180000
#===================== jpa ==================================
spring.jpa.generate-ddl=false
spring.jpa.properties.hibernate.globally_quoted_identifiers=false
spring.jpa.properties.hibernate.generate_statistics=true
spring.jpa.properties.hibernate.session.events.log=false

logging.level.org.hibernate=error
#===================== liquibase =============================
spring.liquibase.change-log=classpath:changelog/changelog-main.xml
spring.liquibase.enabled=${LIQUIBASE_MIGRATION_ENABLE:true}
##=============Lock Manager========================
atp.lock.default.duration.sec=${LOCK_DEFAULT_DURATION_SEC:120}
atp.lock.retry.timeout.sec=${LOCK_RETRY_TIMEOUT_SEC:10800}
atp.lock.retry.pace.sec=${LOCK_RETRY_PACE_SEC:3}
##=============Audit Logging=================
atp.audit.logging.enable=${AUDIT_LOGGING_ENABLE:false}
atp.audit.logging.topic.name=${AUDIT_LOGGING_TOPIC_NAME:audit_logging_topic}
atp.reporting.kafka.producer.bootstrap-server=${KAFKA_REPORTING_SERVERS:kafka:9092}
atp.audit.logging.topic.partitions=${AUDIT_LOGGING_TOPIC_PARTITIONS:1}
atp.audit.logging.topic.replicas=${AUDIT_LOGGING_TOPIC_REPLICAS:3}
#================== websocket ========================================
svp.websocket.buffer-size-limit-mb=${WEBSOCKET_BUFFER_SIZE_LIMIT_MB:20}
svp.websocket.timout-limit-sec=${WEBSOCKET_TIMOUT_LIMIT_SEC:10}

##===================EI GridFS==================
ei.gridfs.database=${EI_GRIDFS_DB:dbname}
ei.gridfs.host=${GRIDFS_DB_ADDR:gridfs.mongocluster.svc}
ei.gridfs.port=${GRIDFS_DB_PORT:27017}
ei.gridfs.user=${EI_GRIDFS_USER:user}
ei.gridfs.password=${EI_GRIDFS_PASSWORD:pass}

## ==============export-import==============
feign.atp.ei.url=${FEIGN_ATP_EI_URL:}
feign.atp.ei.name=${FEIGN_ATP_EI_NAME:ATP-EXPORT-IMPORT}
feign.atp.ei.route=${FEIGN_ATP_EI_ROUTE:api/atp-export-import/v1}

##=============EI CleanJob========================
atp.ei.file.cleanup.job.enable=${EI_CLEAN_JOB_ENABLED:true}
atp.export.workdir=${EI_CLEAN_JOB_WORKDIR:exportimport/node}
atp.ei.file.cleanup.job.fixedRate=${EI_CLEAN_SCHEDULED_JOB_PERIOD_MS:86400000}
atp.ei.file.delete.after.ms=${EI_CLEAN_JOB_FILE_DELETE_AFTER_MS:172800000}
